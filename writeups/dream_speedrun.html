<!--Add date: 02/07/2021-->

<h1>Critique of (Critique of Dream Investigation Results)</h1>

<h2>An Informal Assessment on Modeling</h2>

<h3>Writeup by YR81</h3>

<h4>Introduction and Motivation</h4>

<p>Minecraft is a popular sandbox adventure video game in which players gather resources (e.g., through "mining") and use those resources to build items (i.e. "crafting") with an ultimate goal to defeat a mob known as the "Ender Dragon". As with most video games with a concrete end goal, many players have "speedrun" the game, or attempted to beat it as quickly as possible. One popular Minecraft streamer with the handle Dream [1] recently submitted a series of 6 streams to the Minecraft Speedrunning Leaderboards, which were subsequently investigated for questionable occurrences in the game, particularly in terms of the outcomes of two events - Piglin Barters and Blaze Drops. These events will be discussed in more detail later. The initial review [2] was released and used several basic probability models to show that the maximum likelihood of Dream's streams given an unmodified game is <i>at most</i> 1 in 75 trillion, a very unlikely occurrence indeed.</p>

<p>As a response to this investigation, another report [3] was released by a self-proclaimed graduate from Harvard who was commissioned by Dream to review some of the arguments made by the initial Minecraft Speedrunning Team (MST) report. The response features a wealth of irrelevant details, but we shall focus on one of its main arguments with respect to the original investigation: in particular, the probability distribution used to model event sample spaces.</p>

<p>My intention here is not to rebuke the findings in the response [3] but rather to provide a more nuanced consideration of the arguments it is attempting to make and the impact of those arguments. We begin by explicitly listing these assumptions and defining some terms.</p>

<h4>Definitions and Assumptions</h4>

<p>To be concise in our discussion, let us introduce the following terms and assumptions.</p>

<ol>
    <li>
        <p><b>Piglin Barter</b></p>
        <p>A "Piglin Barter" is an <i>experiment</i> with a set of <i>outcomes</i> that can be described by the item returned. The probabilities of getting specific items (and the quantity thereof) can be found by analyzing the drops table in the file <code>\data\minecraft\loot_tables\gameplay\piglin_bartering.json</code>. For instance, below is the entry for Ender Pearls.</p>
        <img src = "./images/dream_speedrun_1.png">
        <p class = "caption">Figure 1. Entry for Ender Pearls in the Piglin bartering Javascript object file (1.16.1).</p>
    </li>
    <li>
        <p><b>Ender Pearl</b></p>
        <p>An "Ender Pearl" is an event of the Piglin Barter, and for a single trial of the experiment - which costs the player one gold ingot - it is possible to obtain 4, 5, 6, 7, or 8 Ender Pearls. Each of these occurs with probability <code>(1 / 5) (20 / 423) = 4 / 423</code>, which is just under <code>1%</code> for each case. However, disregarding the <i>number</i> of Pearls obtained in each trade, the probability of getting Ender Pearls in a trade is <code>20 / 423</code>.</p>
    </li>
    <li>
        <p><b>Blaze Drop</b></p>
        <p>A "Blaze Drop" is another experiment with sample space {drop, no drop}. Each of these occur with equal probability (again, from analysis of the source code [1]).</p>
    </li>
    <li>
        <p>We assume that the outcomes generated by the RNG for the above experiments are indeed random, and that we can accept the probabilities found by reverse-engineering the source. This cannot be proven with certainty in Dream's speedruns in particular because mob drops are not the only process in the game involving use of the RNG; world-generation and mob spawning also influence the state of the RNG, for example.</p>
        <p>Note that this <i>does not</i> imply that Minecraft's RNG is <i>unpredictable</i> - indeed, it is known that Minecraft makes use of Java's linear congruential generator (LCG), which is inherently predictable. We are only assuming that the results from the experiments can be accurately modeled by the probabilities we have asserted above.</p>
    </li>
</ol>

<p>Now, let's review the probability models used to describe the events in Dream's speedruns and their conclusions.</p>

<h4>Discussion</h4>

<p><i>Observation: Dream obtained a total of 42 Ender Pearls from 262 Piglin Barters.</i></p>

<p>One of the arguments made in [3] is that the binomial distribution used in [2] is invalid because the player will stop after obtaining the necessary 12 Ender Pearls for the End portal; therefore, the trials are not actually independent, which the binomial distribution requires.</p>

<p>To assess this claim, let's perform a one-sided test of significance <code>H0 = frequency of {return = Ender Pearl} == 20 / 423</code> and <code>H1 = frequency of {return = Ender Pearl} > 20 / 423</code> and a significance level <code>a</code> (we won't specify <code>a</code> here since it is largely based on individual opinion and confidence - is 1 in 1 million enough to justify cheating? is 1 in 75 trillion? :)). We will only compute the p-values associated with Dream's outcome using each distribution and compare their values.</p>

<h5>Binomial Distribution</h5>

<p>We start by assuming a binomial distribution, the mechanics of which are not presented here but can be found in any introductory statistics text. Let's compute the probability of getting a result as rare, or more rare, than the observation. In other words, we want to find the probability that in a random series of 262 barters, 42 or more end up returning Ender Pearls. It is not hard to see that this is just</p>

<img class = "small" src = "./images/dream_speedrun_2.png">

<p>where <code>N = 262</code> is the number of trials, <code>x = 42</code> is the total number of successful Ender Pearl trades, and <code>p = 20 / 423</code>. Evaluating, we find that <code>P_\text{binom} ~ 5.58 x 10^{-12}</code>, or 1 in 180 trillion, the same result as obtained in [2].</p>

<h5>"Barter Stop" Distribution (a.k.a. Negative Binomial)</h5>

<p>The response proposed another distribution, which the author refers to as the "barter stop" distribution [3], that more accurately reflects the experiment. In this distribution, the number of trials are repeated until a predetermined number of successes (in this case, the number of Pearls needed for End portal activation) are achieved. In fact, this is nothing other than the well-known <a href = "https://en.wikipedia.org/wiki/Negative_binomial_distribution" target = "_blank">negative binomial distribution</a>, and we shall use this term from here on. The author of [3] claims that this distribution is more accurate than the binomial distribution because a player stops the experiment whenever a certain number of items has been obtained. The author of [3] further claims that this changes the p-value "by a factor of 100" without providing details beyond a perfunctory plot of the PMF for an approximated binomial and simulated negative binomial distribution.</p>

<p>To evaluate the negative binomial model, we need to take a look at the individual trials and make some assumptions about Dream's intentions. The astute reader will question why the motives matter; the results are the results whether or not Dream decided to have a pizza that day or not, so why should we care about what his intentions were? If we are going to <i>precisely</i> compute p-values associated with the negative binomial distribution, then we must assume that Dream was going after a certain number of Ender Pearls (also known as the "Stopping Criterion" in the initial investigation [2]).</p>

<p>Below are the documented trades and Pearl amounts for each of the barters monitored in the six speedruns of interest:</p>

<img src = "./images/dream_speedrun_3.png">

<p class = "caption">Figure 2. Precise outcomes of bartering runs in Dream's speedruns.</p>

<p>As suggested in the response [3], we will assume that on each occasion, Dream was trying to get 10 Pearls. That is, once he obtains 10 or more Pearls, he will immediately stop. Of course, we will ignore empty barters that resulted in no Pearls (there are two). We will also adjust this rule for instances where the barter resulted in less than 10 Pearls, of which there were three (single trades of 5, 7, and 4), in which case we will assume he was going after 4 Pearls. Finally, as a challenge for ourselves, we will artifically assign the target value of 24 for Dream's run of 26 Ender Pearl outcomes (we obviously cannot explain that run if he was just going for 10). We still maintain that different bartering runs are independent.</p>

<p>To begin, what is relevant for the computation of the p-value using the negative binomial distribution? It turns out that with the modeling assumptions above, we require even less information than for the binomial approximation. In particular, we only need the number of trials for each experiment, and the p-value is the probability the number of trials by which at least 10 Ender Pearls are obtained is equal to or <i>fewer</i> than the number of trials Dream had to take. That may sound confusing, but essentially we want to find the probability that we can get 10 or more Ender Pearls as soon as or earlier than Dream did. Consider the second row in Figure 2 for example: Dream only had to expend <i>5 ingots</i> to exceed his goal. Seems unlikely, right? Let's see.</p>

<p>The p-value computation now becomes slightly more complicated, but nothing that warrants the need for a simulation as suggested in [3]. That is because there are an easily countable number of ways to get to or immediately exceed 10. We can list them exhaustively here:</p>

<ul>
    <li><p>4 + 4..5 + 4..8</p></li>
    <li><p>4 + 6..8</p></li>
    <li><p>5 + 4 + 4..8</p></li>
    <li><p>5 + 5..8</p></li>
    <li><p>6..8 + 4..8</p></li>
</ul>

<p>The double dots in the above represent any value between the surrounding values, inclusive. For instance, the third line describes the case where we start out by getting a trade of 5, then get 4, and finally require a trade of any amount to reach the goal. It is not hard to convince oneself that this list is exhaustive. Now comes the fun part: for a given number of trials <i>N</i>, we want to fit one of these combinations along with no-luck trades such that the goal is reached by exactly <i>N</i> trials - note the last trial must be successful, by our model assumption. This gives the probability mass function (PMF) of our negative binomial distribution.</p>

<p>First, we observe that it is impossible to reach the goal with a single trial. This is obvious. It is possible with 2 trials, but both of them must be successful. Rows 2, 4, and 5 give the cases. The probability can be shown to be</p>

<img class = "small" src = "./images/dream_speedrun_4.png">

<p>where <code>p = 4 / 423</code> (note that this is different from the binomial model because we are now considering specific values of the Ender Pearl trades). It is more likely with 3 trials: we consider all the listed cases and pad the cases with fewer than three required trials with the fail probability <code>1 - 5 p</code>.</p>

<img class = "small" src = "./images/dream_speedrun_5.png">

<p>Every value of <code>N</code> beyond 3 can be treated the same way. We fix the last trial to be a success, pick one or two of the previous trials to be other successes depending on the case in the list above, and fill the rest with fails. The general expression for <code>N = n</code> is</p>

<img class = "small" src = "./images/dream_speedrun_6.png">

<p>Now that we have the PMF, obtaining the CDF is trivial; we can write it in a short script:</p>

<pre class = "python">
def nbinompmf10(n):
	assert isinstance(n, int)
	p = 4 / 423
	if n < 2:
		return 0
		
	if n == 2:
		return (3 + 4 + 3 * 5) * p**2
		
	# don't actually need a separate case for n = 3
	return ((n - 1) * (n - 2) / 2) * (10 + 5) * p**3 * (1 - 5 * p)**(n - 3) + 
	(n - 1) * (3 + 4 + 3 * 5) * p**2 * (1 - 5 * p)**(n - 2)
	
# probability that success before or by n trials
def nbinomcdf10(n):
	assert isinstance(n, int)
	if n < 2:
		return 0
		
	ret = 0
	for i in range(2, n + 1):
		ret += nbinompmf10(i)
		
	return ret
</pre>

<p>We can now call <code>nbinomcdf10(...)</code> to determine the p-value for any one of the 10-Pearl experiments. They are tabulated below.</p>

<table>
    <tr>
        <th><p>Trial</p></th>
        <th><p>Length</p></th>
        <th><p><code>P_\text{nbinom}</code></p></th>
    </tr>
    <tr>
        <td><p>1</p></td>
        <td><p>22</p></td>
        <td><p><code>2.56 x 10^{-1}</code></p></td>
    </tr>
    <tr>
        <td><p>2</p></td>
        <td><p>5</p></td>
        <td><p><code>1.80 x 10^{-2}</code></p></td>
    </tr>
    <tr>
        <td><p>3</p></td>
        <td><p>24</p></td>
        <td><p><code>2.89 x 10^{-1}</code></p></td>
    </tr>
    <tr>
        <td><p>4</p></td>
        <td><p>18</p></td>
        <td><p><code>1.89 x 10^{-1}</code></p></td>
    </tr>
    <tr>
        <td><p>7</p></td>
        <td><p>7</p></td>
        <td><p><code>3.56 x 10^{-2}</code></p></td>
    </tr>
    <tr>
        <td><p>9</p></td>
        <td><p>26</p></td>
        <td><p><code>3.23 x 10^{-1}</code></p></td>
    </tr>
    <tr>
        <td><p>10</p></td>
        <td><p>8</p></td>
        <td><p><code>4.61 x 10^{-2}</code></p></td>
    </tr>
    <tr>
        <td><p>11</p></td>
        <td><p>5</p></td>
        <td><p><code>1.80 x 10^{-2}</code></p></td>
    </tr>
    <tr>
        <td><p>12</p></td>
        <td><p>20</p></td>
        <td><p><code>2.22 x 10^{-1}</code></p></td>
    </tr>
    <tr>
        <td><p>15</p></td>
        <td><p>10</p></td>
        <td><p><code>7.00 x 10^{-2}</code></p></td>
    </tr>
    <tr>
        <td><p>16</p></td>
        <td><p>10</p></td>
        <td><p><code>7.00 x 10^{-2}</code></p></td>
    </tr>
    <tr>
        <td><p>17</p></td>
        <td><p>21</p></td>
        <td><p><code>2.39 x 10^{-1}</code></p></td>
    </tr>
    <tr>
        <td><p>18</p></td>
        <td><p>20</p></td>
        <td><p><code>2.22 x 10^{-1}</code></p></td>
    </tr>
    <tr>
        <td><p>19</p></td>
        <td><p>10</p></td>
        <td><p><code>7.00 x 10^{-2}</code></p></td>
    </tr>
    <tr>
        <td><p>21</p></td>
        <td><p>18</p></td>
        <td><p><code>1.89 x 10^{-1}</code></p></td>
    </tr>
    <tr>
        <td><p>22</p></td>
        <td><p>3</p></td>
        <td><p><code>5.73 x 10^{-3}</code></p></td>
    </tr>
</table>

<p>What about for cases other than <code>10</code>, such as for the exaggerated case of <code>24</code>? Enumerating all of the cases would be a nightmare. Fortunately, there is still a "closed-form" solution to it, and it is based on the crucial observation that <i>the probability of reaching the goal before or on <code>N</code> trials is identical to the probability of getting an arbitrary list of length <code>N</code> with sum greater than or equal to the goal</i>. In other words, instead of restricting the sample space to only sequences that end in a success, we can instead count all possible sequences with a sum restriction. It turns out that this, too, has an associated probability distribution, and it is called the <a href = "https://en.wikipedia.org/wiki/Multinomial_distribution" target = "_blank">multinomial distribution</a>. Its CDF can be systematically calculated for this particular situation as follows:</p>

<img src = "./images/dream_speedrun_7.png">

<pre class = "python">
def multinomCDF(N, x):
	import numpy as np
	assert isinstance(N, int) and isinstance(x, int)
	p = 4 / 423
	addends = []
	for i in range((x - 1) // 8 + 1):
		for j in range((x - 1 - (8 * i)) // 7 + 1):
			for k in range((x - 1 - (8 * i + 7 * j)) // 6 + 1):
				for l in range((x - 1 - (8 * i + 7 * j + 6 * k)) // 5 + 1):
					for m in range((x - 1 - (8 * i + 7 * j + 6 * k + 5 * l)) // 4 + 1):
						if i + j + k + l + m > N:		#impossible
							continue
							
						multinomCoeff = np.math.factorial(N) / (np.math.factorial(i) * np.math.factorial(j) * np.math.factorial(k) * np.math.factorial(l) * np.math.factorial(m) * np.math.factorial(N - (i + j + k + l + m)))
						probPi = np.power(p, i + j + k + l + m) * np.power(1 - 5 * p, N - (i + j + k + l + m))
						addends.append(multinomCoeff * probPi)
						
	addends.sort()
	return sum(addends)
</pre>

<p>In the above, <code>N</code> is the size of the sequence and <code>x</code> is the target. All we have to do is take the complement, since we want the probability of getting a sum <i>greater than</i> or equal to the target. It is easily verified that the output of the above <code>1 - multinomCDF(..., 10)</code> is identical (up to truncation error) to <code>nbinomcdf(...)</code>. But the power in the multinomial distribution lies in its ability to easily use an arbitrary target. Looking back at the speedrun data, Dream reached the supposed target of <code>24</code> just with <code>12</code> trials. The p-value associated with this is a mere <code>1.21 x 10^{-3}</code>, or about 1 in 826. On the other hand, we can also evaluate the p-value for the small barters, for which we assume the target was <code>4</code>. In the first situation, Dream bartered once to get 5 Pearls; the p-value of this is simply the overall Pearl probability <code>20 / 423 ~ 4.73 x 10^{-2}</code>. In the second situation, Dream had to barter <code>13</code> times to reach the target; the p-value of this is much higher, at <code>4.67 x 10^{-1}</code>. Finally, Dream bartered <code>4</code> times to reach the target, for a p-value of <code>1.35 x 10^{-1}</code>.</p>

<p>Now that we have p-values from independent experiments, we can combine them to compare the results with the binomial distribution. How do we do this? We cannot simply multiply the p-values, since this naturally leads to a significant outcome from insignificant results. Rather, we apply <a href = "https://en.wikipedia.org/wiki/Fisher%27s_method" target = "_blank">Fisher's method</a>, which uses a Chi-square test statistic. We simply take the natural logarithms of all the p-values, sum them together, and multiply by <code>-2</code> to obtain the statistic. Doing this for our data, we get <code>X^2_{42} = 107</code>. This corresponds to <code>P = 1.15 x 10^{-7}</code> (1 in 8.7 million), which is about 20,000 times greater than the result obtained from the binomial approximation.</p>

<h5>Explanations for Discrepancy</h5>

<p>Why is the p-value from the negative binomial calculation so much higher than the binomial calculation? Let's revisit the data was considered for each case. In the binomial approximation, we completely disregarded Dream's motives and the specific Pearl amounts for each barter, and we only considered the ratio of Ender Pearl barters to total barters. In the negative binomial calcualation, we actually ignored all data except for the number of trials made during each run. We also assumed that Dream was going after a certain number of Pearls, so we took into account the specific amounts of Pearls obtainable during each barter.</p>

<p>However, the assumptions we made in the negative binomial may be flawed. For example, we assumed Dream was aiming for 10 Pearls in each run, but this may not have actually been the case. Recalculating with a target of 11 or 12 Pearls decreases the p-value by several orders of magnitude, towards the binomial case.</p>

<p>Additionally, when applying the data for the negative binomial distribution, we assumed that success was not obtained <i>until the last trial was performed</i>; i.e., all of the ingots in the first column of Figure 2 needed to be bartered to reach the goal. This is not a very accurate assumption at all, given that in most cases, Dream drops multiple ingots at a time rather than waiting for the result of each trial, as is assumed by negative binomial.</p>

<p>In general, due to the shakiness of its assumptions in this particular situation, there is <i>no reason</i> to believe that the p-value obtained from the negative binomial is more accurate than the result from the binomial calculation. Ultimately, the bigger the target number of Pearls becomes, the closer the results from the two models become as well. Unless additional observations can be made about the exact times that Dream obtained the target number of Pearls (i.e., by revisiting the gameplay footage), we maintain that the result from the binomial test is more accurate.</p>

<p>Regardless of how accurate the assumptions are, we can make the claim that the result from the negative binomial is a <i>conservative</i> estimate on the p-value; that is, the actual p-value should be strictly lower than <code>1.15 x 10^{-7}</code>, since we have given all benefit of the doubt to Dream by assuming a low target amount of 10 for each run and that he had to expend all of the ingots in each run to reach the target.</p>

<h4>Conclusions</h4>

<p>In general, the respose [3] attempts to invalidate claims in the original investigation [2] by introducing alternative statistical models and seemingly complex corrections. But beyond the statements of these alternative models, there is simply too much hand-waving and not enough <i>significant mathematical evidence</i> to suggest that these assumptions deem the original approximations inaccurate. The report itself claims (somewhat self-righteously!) that "[p]robability calculations are hard". My question is this: why make it harder, and not even necessarily more accurate, given the uncertainty around the assumptions? The takeaway: it's time we stop making inference harder than it needs to be, and <i>stop playing around with statistics willy-nilly, using one distribution where it seems to give better p-values and another because it allows the author to sound more sophisticated</i>, without carefully providing evidence to support the models.</p>

<h4>References</h4>

<ol>
    <li><p>Dream's <a href = "https://www.twitch.tv/dreamwastaken" target = "_blank">Twitch channel</a>.</p></li>
    <li><p>Minecraft Speedrunning Team, <a href = "https://mcspeedrun.com/dream.pdf" target = "_blank">"Dream Investigation Results"</a> <b>2020</b>.</p></li>
    <li><p>Photoexcitation, <a href = "https://drive.google.com/file/d/1yfLURFdDhMfrvI2cFMdYM8f_M_IRoAlM/view" target = "_blank">"Critique of Dream Investigation Results"</a> <b>2020</b>.</p></li>
</ol>